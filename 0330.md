### *데이터 분석 분류
 - 머신러닝(기계학습)
사용자가 직접 데이터의 패턴, rule을 찾지 않고 데이터의 학습을 통해 자동으로 패턴을 찾을 수 있도록 하는 분석기법

#### 1.지도학습
- x-y
 =>y에 영향을 미치는 설명변수의 최적의 조합을 찾는 과정 (변수의 선택 및 제거, 변수의 결합 및 변형)
 ex) c1=(x1+x2)/2, c2=log(x1)
##### 1)회귀기반 모델(y가 연속형): 부동산 가격 예측, 수요예측...
##### 2)분류기반 모델(y가 범주형): 생존여부 예측, 이탈여부 예측...

#### 2.비지도학습 
- y가 존재하지 않음
- x~=>x들이 갖는 각 관측자의 유사성 기반 데이터의 세분화
----------------

#### [참고] 딥러닝
- 머신러닝의 일부, 딥러님에 대한 연구가 강화되면서 기존 머신러닝에서 분리하여 설명하는 추세, 주로 인공신경망 모델을 사용한 분석 기법을 의미, 머신러닝에 비해 비정형화된 데이터 처리에 용이
- 딥러닝은 이미지 음성 영상의 비정형데이터의 분석을 다룬다
(비정형 데이터: 테이블에 표현할 수 없는 데이터)
----------
#### *분류분석(비통계적 분석기법)

- 지도학습(y가 범주형)
- x들이 가지는 패턴에 따라 y의 종류를 예측하기 위한 분석

##### #분류분석 과정
1) 변수 데이터 수집(y에 영향을 미칠만한 모든 데이터)
2) 변수연구(feature selection 변수결합/변수변형)
3) 이상치 및 결측치 처리
- 위쪽은 경험적 충족되는 산물
4) 모델선택 <-중점적으로 설명한다 앞으로
5) data sampling(train set/validation set/test set)
6) 모델학습(train set)
7) 모델평가(test set)
8) 실제정답과 예측값의 일치율로 평가
9) 모델튜닝(validation set)
10) 결과해석

----------
```r
# Y(이탈/비이탈)=X1+2X2+3X3..X100
#              Y        X
# 수집 data:  안다      X1,X2,X3...
#    학습용:  안다      X1,X2,X3...
#    평가용:  안다      X1,X2,X3...
# new data:   모름      x1,x2,x3...
```
------
##### 1)decision tree(의사결정나무)
 -분류분석을 수행하는 트리기반 모델의 가장 초기 모델
 -한번의 패턴확인(하나의 트리로)으로 y를 예측
 -패턴이 tree 구조를 함
 -비통계적 모델로 모델 적용 및 해석이 매우 쉽다
 -단일의사결정이므로 예측력이 불안하거나 overfit될 수 있음

##### 2)Random Forest
- 위 모델을 다중으로 넓힌 모델,1인찬스<100인 찬스
- overfit발생
(tree구조가 복잡할수록 깊은 사고에서 오는 예측률을 떨어뜨리는 현상으로 trian data에 대한 과대한 예측률이 새로운 데이터에 대해서는 예측력을 떨어지는 것) 
=> 그래서 상위에서 가장 중요한 질문을 던져 단계를 줄인다
```r
#[iris data set-DT]
install.packages('rpart')
library(rpart)

m_dt <- rpart(Species ~., data=iris) # .:앞변수 제외 모든 의미

#모델 확인(각 노드의 분류율 및 설명변수의 선택과정)
# 많이 포함된 것을 대표로 표현,동일비율일 때는 맨 앞에가 대표됨
# 분류조건, 들어온갯수, 오분류갯수, 분류된 비율, *(분류완료표시)
m_dt  
>
n= 150 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

1) root 150 100 setosa (0.33333333 0.33333333 0.33333333)  
  2) Petal.Length< 2.45 50   0 setosa (1.00000000 0.00000000 0.00000000) *
  3) Petal.Length>=2.45 100  50 versicolor (0.00000000 0.50000000 0.50000000)  
    6) Petal.Width< 1.75 54   5 versicolor (0.00000000 0.90740741 0.09259259) *
    7) Petal.Width>=1.75 46   1 virginica (0.00000000 0.02173913 0.97826087) *


unique(iris$Species)
>
[1] setosa     versicolor virginica 
Levels: setosa versicolor virginica

#모델 시각화 
dev.new()
plot(m_dt,compress = T) # 선만 그려짐
text(m_dt,cex=1.5) # 텍스트 붙어짐, 오분류까지 확인이 어려워 패키지 사용해야함

install.packages('rpart.plot')
library(rpart.plot)

prp(m_dt,type = 4,   #어떤 형식으로 출력인가
    extra = 2,       #어떤 정보를 표현할 것인가
    digits = 3)      #자릿수표현 인자, 메뉴얼에서 자세히 확인가능

#모델을 통한 새로운 데이터에 대한 Y값 예측
iris_new<-data.frame(Sepal.Length=4.7,
                     Sepal.Width=3.8,
                     Petal.Length=1.9,
                     Petal.Width=0.3)

predict(m_dt,newdata = iris_new,type = 'class') # >>setosa출력
>
     1 
setosa 
Levels: setosa versicolor virginica

#이제는 특정 데이터에 대한 것이 아닌 여러 데이터에 대한 sampling해서
#train과 test 셋으로 나눈 후 학습결과 보기
# 1. sampling(train과 test 셋으로 나누기)
v_rn<-sample(1:nrow(iris),size = nrow(iris)*0.7)
iris_train<-iris[v_rn,]
iris_test<-iris[-v_rn,]

# 2.모델생성(training, pattern 추출)
m_dt <- rpart(Species ~., data=iris_train) 

# 3. 모델 시각화 - 아까함 skip
# 4. 모델 평가(train으로 학습한 모델에 test set을 넣어 예측값을
#             얻고 예측률 평가)
v_y<-iris_test$Species
v_predict<-(predict(m_dt,newdata = iris_test,type = 'class'))
#test data에 y값이 있더라도 formula에 고정된 설명변수만 가져가기 
#때문에 그냥 넣어도 된다
>
 7         13         17         30         32         34         38         45         46         57         62         64 
    setosa     setosa     setosa     setosa     setosa     setosa     setosa     setosa     setosa versicolor versicolor versicolor 
    ...

sum(v_y==v_predict)/nrow(iris_test)*100
>
[1] 93.33333

# 5.모델 튜닝
#1)매개변수 값 확인
m_dt$control #튜닝과 관련된 기본값
>
$minsplit
[1] 20

$minbucket
[1] 7

$cp
[1] 0.01

$maxdepth
[1] 30
...

#2)매개변수 종류
# 1-1)minbucket: 추가분류하는 기준이 되는 오분류 갯수  
# 추가 하위 노드를 생성하기 위한 오분류 데이터의 최소 기준
# 값이 7인 경우 오분류 데이터가 7미만일 경우는 더이상 분류하지 x
# 값이 작을수록 모델의 복잡도는 커짐
# 1-2)minsplit
round(minbucket/3) ???????????????????????????????????????????

#3)매개변수 조정
m_dt2<-rpart(Species ~., data=iris_train,
         control = rpart.control(minbucket = 2))
m_dt2
>
n= 105 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

 1) root 105 64 setosa (0.39047619 0.31428571 0.29523810)  
   2) Petal.Length< 2.6 41  0 setosa (1.00000000 0.00000000 0.00000000) *
   3) Petal.Length>=2.6 64 31 versicolor (0.00000000 0.51562500 0.48437500)  
     6) Petal.Width< 1.65 36  3 versicolor (0.00000000 0.91666667 0.08333333)  
      12) Petal.Length< 4.95 32  0 versicolor (0.00000000 1.00000000 0.00000000) *
      13) Petal.Length>=4.95 4  1 virginica (0.00000000 0.25000000 0.75000000) *
     7) Petal.Width>=1.65 28  0 virginica (0.00000000 0.00000000 1.00000000) *
```
--------------
```r
#3)최적의 매개변수 값 확인
# [연습문제 - minbucket이 1-10 변화될때의 예측력 변화 확인]
# overfit 여부 
# **overfit(과대적합): train data set에 대한 예측을 과도하게 강하게
# 함으로 인해 모델이 복잡하져 새로운 데이터에 대한 예측력(testdata)
# 과의 차이가 꽤 발생하게 되는 경우를 의미
m_dt3<-rpart(Species ~., data=iris_train,
             control = rpart.control(minbucket = 1))

v1<-c()
v2<-c()
for (i in 1:10) {
  m_dt3<-rpart(Species ~., data=iris_train,
               control = rpart.control(minbucket = i))
  tp<-predict(m_dt3,newdata = iris_train,type = 'class')
  v1<-c(v1,sum(iris_train$Species==tp)/nrow(iris_train)*100)
  
  tep<-predict(m_dt3,newdata = iris_test,type = 'class')
  v2<-c(v2,sum(iris_test$Species==tep)/nrow(iris_test)*100)
}

df1<-data.frame(train예측=v1,
                test예측=v2)

##시각화##
dev.new()
plot(df1$train예측,type='o',col=1,ylim=c(0,100),axes=F,ann=F)
lines(df1$test예측,type='o',col=2,ylim=c(0,100))


